{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mugalan/classical-mechanics-from-a-geometric-point-of-view/blob/main/rigid-body-control/RigidBodyIntinsicEKF_DHSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rigid Body Intrinsic EKF"
      ],
      "metadata": {
        "id": "xKy4CKmkJ5vG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqSk1gQrwgIR"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.integrate import odeint\n",
        "import math\n",
        "from numpy import linalg\n",
        "import sympy\n",
        "from sympy import symbols\n",
        "from sympy import *\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from sympy.physics.mechanics import dynamicsymbols, init_vprinting\n",
        "from IPython.display import display, Math, Latex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KFShapeError(ValueError):\n",
        "    pass\n",
        "\n",
        "class KFValueError(ValueError):\n",
        "    pass\n",
        "\n",
        "class LinearKF:\n",
        "    \"\"\"\n",
        "    Linear-Gaussian Kalman Filter utilities focused on the measurement update.\n",
        "\n",
        "    Notation (matching your equations):\n",
        "        m_k^- : predicted mean      (n,)\n",
        "        P_k^- : predicted covariance (n,n)\n",
        "        H_k   : measurement matrix   (p,n)\n",
        "        y_k   : measurement vector   (p,)\n",
        "        Σ_m   : measurement noise covariance R (p,p)\n",
        "\n",
        "    Update:\n",
        "        K_k = P_k^- H_k^T (H_k P_k^- H_k^T + Σ_m)^{-1}\n",
        "        m_k = m_k^- + K_k (y_k - H_k m_k^-)\n",
        "        P_k = (I - K_k H_k) P_k^-      (or Joseph form)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, use_joseph: bool = True, symmetrize: bool = True, atol_sym: float = 1e-10):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        use_joseph : bool\n",
        "            Use Joseph-stabilized covariance update (default True).\n",
        "        symmetrize : bool\n",
        "            Force symmetry of P_k at the end via (P + P^T)/2 (default True).\n",
        "        atol_sym : float\n",
        "            Tolerance for symmetry checks.\n",
        "        \"\"\"\n",
        "        self.use_joseph = use_joseph\n",
        "        self.symmetrize = symmetrize\n",
        "        self.atol_sym = atol_sym\n",
        "\n",
        "    # ---------- public API ----------\n",
        "\n",
        "    def measurement_update(self, m_pred, P_pred, H, y, R):\n",
        "        \"\"\"\n",
        "        Compute K_k, m_k, P_k given m_k^-, P_k^-, H_k, y_k, Σ_m (=R).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        m_upd : (n,)\n",
        "        P_upd : (n,n)\n",
        "        K     : (n,p)\n",
        "        S     : (p,p)   innovation covariance = H P^- H^T + R\n",
        "        \"\"\"\n",
        "        m_pred, P_pred, H, y, R, n, p = self._validate_shapes(m_pred, P_pred, H, y, R)\n",
        "\n",
        "        # Symmetry checks and SPD requirements\n",
        "        self._assert_symmetric(P_pred, \"P_pred\", atol=self.atol_sym)\n",
        "        self._assert_symmetric(R, \"R\", atol=self.atol_sym)\n",
        "        _ = self._assert_spd(R, \"R\")  # R must be SPD\n",
        "\n",
        "        # Innovation covariance S = H P^- H^T + R\n",
        "        HP = H @ P_pred               # (p,n)\n",
        "        S = HP @ H.T + R              # (p,p)\n",
        "        try:\n",
        "            Ls = np.linalg.cholesky(S)\n",
        "        except np.linalg.LinAlgError as e:\n",
        "            raise KFValueError(\n",
        "                f\"Innovation covariance `S` is not SPD. \"\n",
        "                f\"Check H, P_pred, and R. Cholesky failed: {e}\"\n",
        "            )\n",
        "\n",
        "        # Gain K = P^- H^T S^{-1} without explicit inverse\n",
        "        U = np.linalg.solve(Ls, HP)   # (p,n)\n",
        "        X = np.linalg.solve(Ls.T, U)  # (p,n)\n",
        "        K = X.T                       # (n,p)\n",
        "\n",
        "        # Residual\n",
        "        v = y - H @ m_pred            # (p,)\n",
        "\n",
        "        # Updated mean\n",
        "        m_upd = m_pred + K @ v        # (n,)\n",
        "\n",
        "        # Updated covariance\n",
        "        I = np.eye(n)\n",
        "        if self.use_joseph:\n",
        "            I_KH = (I - K @ H)\n",
        "            P_upd = I_KH @ P_pred @ I_KH.T + K @ R @ K.T\n",
        "        else:\n",
        "            P_upd = (I - K @ H) @ P_pred\n",
        "\n",
        "        if self.symmetrize:\n",
        "            P_upd = 0.5 * (P_upd + P_upd.T)\n",
        "\n",
        "        return m_upd, P_upd, K, S\n",
        "\n",
        "    def innovation(self, m_pred, P_pred, H, R, y=None):\n",
        "        \"\"\"\n",
        "        Compute innovation covariance S = H P^- H^T + R and (optionally) residual v.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        (v, S) if y is given; otherwise just S.\n",
        "        \"\"\"\n",
        "        # Validate without using y unless provided\n",
        "        m_pred = self._as_1d(m_pred, \"m_pred\")\n",
        "        P_pred = self._as_2d(P_pred, \"P_pred\")\n",
        "        H = self._as_2d(H, \"H\")\n",
        "        R = self._as_2d(R, \"R\")\n",
        "\n",
        "        n = m_pred.shape[0]\n",
        "        if P_pred.shape != (n, n):\n",
        "            raise KFShapeError(f\"`P_pred` must have shape {(n, n)}; got {P_pred.shape}.\")\n",
        "        if H.shape[1] != n:\n",
        "            raise KFShapeError(f\"`H` second dim must be {n}; got {H.shape}.\")\n",
        "\n",
        "        p = H.shape[0]\n",
        "        if R.shape != (p, p):\n",
        "            raise KFShapeError(f\"`R` must have shape {(p, p)}; got {R.shape}.\")\n",
        "\n",
        "        self._assert_symmetric(P_pred, \"P_pred\", atol=self.atol_sym)\n",
        "        self._assert_symmetric(R, \"R\", atol=self.atol_sym)\n",
        "        _ = self._assert_spd(R, \"R\")\n",
        "\n",
        "        S = H @ P_pred @ H.T + R\n",
        "        if y is None:\n",
        "            return S\n",
        "        y = self._as_1d(y, \"y\")\n",
        "        if y.shape[0] != p:\n",
        "            raise KFShapeError(f\"`y` length must be {p}; got {y.shape}.\")\n",
        "        v = y - H @ m_pred\n",
        "        return v, S\n",
        "\n",
        "    def set_options(self, *, use_joseph=None, symmetrize=None, atol_sym=None):\n",
        "        \"\"\"Update instance options.\"\"\"\n",
        "        if use_joseph is not None:\n",
        "            self.use_joseph = bool(use_joseph)\n",
        "        if symmetrize is not None:\n",
        "            self.symmetrize = bool(symmetrize)\n",
        "        if atol_sym is not None:\n",
        "            self.atol_sym = float(atol_sym)\n",
        "\n",
        "    # ---------- helpers (static) ----------\n",
        "\n",
        "    @staticmethod\n",
        "    def _as_1d(x, name):\n",
        "        x = np.asarray(x, dtype=float)\n",
        "        if x.ndim == 2 and x.shape[1] == 1:\n",
        "            x = x[:, 0]\n",
        "        if x.ndim != 1:\n",
        "            raise KFShapeError(f\"`{name}` must be a 1D vector of shape (n,) or (n,1); got {x.shape}.\")\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _as_2d(x, name):\n",
        "        x = np.asarray(x, dtype=float)\n",
        "        if x.ndim != 2:\n",
        "            raise KFShapeError(f\"`{name}` must be a 2D array; got {x.ndim}D with shape {x.shape}.\")\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _assert_symmetric(M, name, atol=1e-10):\n",
        "        if M.shape[0] != M.shape[1]:\n",
        "            raise KFShapeError(f\"`{name}` must be square; got {M.shape}.\")\n",
        "        if not np.allclose(M, M.T, atol=atol):\n",
        "            raise KFValueError(f\"`{name}` must be symmetric within atol={atol}.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _assert_spd(M, name):\n",
        "        try:\n",
        "            return np.linalg.cholesky(M)\n",
        "        except np.linalg.LinAlgError as e:\n",
        "            raise KFValueError(f\"`{name}` must be symmetric positive definite (SPD). Cholesky failed: {e}\")\n",
        "\n",
        "    # ---------- internal ----------\n",
        "\n",
        "    def _validate_shapes(self, m_pred, P_pred, H, y, R):\n",
        "        m_pred = self._as_1d(m_pred, \"m_pred\")\n",
        "        y = self._as_1d(y, \"y\")\n",
        "        P_pred = self._as_2d(P_pred, \"P_pred\")\n",
        "        H = self._as_2d(H, \"H\")\n",
        "        R = self._as_2d(R, \"R\")\n",
        "\n",
        "        n = m_pred.shape[0]\n",
        "        if P_pred.shape != (n, n):\n",
        "            raise KFShapeError(f\"`P_pred` must have shape {(n, n)} to match `m_pred`; got {P_pred.shape}.\")\n",
        "        if H.shape[1] != n:\n",
        "            raise KFShapeError(f\"Second dim of `H` must equal len(m_pred)={n}; got H.shape={H.shape}.\")\n",
        "        p = H.shape[0]\n",
        "        if y.shape[0] != p:\n",
        "            raise KFShapeError(f\"`y` length must match number of rows in `H` (p={p}); got y.shape={y.shape}.\")\n",
        "        if R.shape != (p, p):\n",
        "            raise KFShapeError(f\"`R` must have shape {(p, p)}; got {R.shape}.\")\n",
        "        return m_pred, P_pred, H, y, R, n, p"
      ],
      "metadata": {
        "id": "iNp8KsJlw_y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LDSShapeError(ValueError): ...\n",
        "class LDSValueError(ValueError): ...\n",
        "\n",
        "class LinearGaussianSystemSyms:\n",
        "    \"\"\"\n",
        "    Discrete-time linear Gaussian system:\n",
        "        x_k = A_k x_{k-1} + w_{k-1},   w_{k-1} ~ N(0, Σ_p)\n",
        "        y_k = H_k x_k       + z_k,     z_k     ~ N(0, Σ_m)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, A, H, Sigma_p, Sigma_m, x0=None, rng=None):\n",
        "        self.A = self._as_2d(A, \"A\")\n",
        "        self.H = self._as_2d(H, \"H\")\n",
        "        self.Sigma_p = self._as_2d(Sigma_p, \"Sigma_p\")\n",
        "        self.Sigma_m = self._as_2d(Sigma_m, \"Sigma_m\")\n",
        "\n",
        "        n = self.A.shape[0]\n",
        "        p = self.H.shape[0]\n",
        "\n",
        "        # Shape checks\n",
        "        if self.A.shape != (n, n):\n",
        "            raise LDSShapeError(f\"`A` must be (n,n); got {self.A.shape}.\")\n",
        "        if self.H.shape[1] != n:\n",
        "            raise LDSShapeError(f\"`H` must be (p,n) with n={n}; got {self.H.shape}.\")\n",
        "        if self.Sigma_p.shape != (n, n):\n",
        "            raise LDSShapeError(f\"`Sigma_p` must be (n,n); got {self.Sigma_p.shape}.\")\n",
        "        if self.Sigma_m.shape != (p, p):\n",
        "            raise LDSShapeError(f\"`Sigma_m` must be (p,p); got {self.Sigma_m.shape}.\")\n",
        "\n",
        "        # Symmetry + SPD\n",
        "        self._assert_symmetric(self.Sigma_p, \"Sigma_p\")\n",
        "        self._assert_symmetric(self.Sigma_m, \"Sigma_m\")\n",
        "        self.Lp = self._assert_spd(self.Sigma_p, \"Sigma_p\")  # Cholesky factors for sampling\n",
        "        self.Lm = self._assert_spd(self.Sigma_m, \"Sigma_m\")\n",
        "\n",
        "        self.n, self.p = n, p\n",
        "        self.rng = rng if isinstance(rng, np.random.Generator) else np.random.default_rng(rng)\n",
        "        self.x = self._as_1d(x0, \"x0\") if x0 is not None else np.zeros(n)\n",
        "\n",
        "    # ---------- stepping ----------\n",
        "\n",
        "    def step_state(self):\n",
        "        \"\"\"x_k = A x_{k-1} + w_{k-1}  (returns x_k)\"\"\"\n",
        "        w = self.Lp @ self.rng.standard_normal(self.n)\n",
        "        self.x = self.A @ self.x + w\n",
        "        return self.x\n",
        "\n",
        "    def step_measurement(self, x=None):\n",
        "        \"\"\"y_k = H x_k + z_k  (returns y_k)\"\"\"\n",
        "        xk = self._as_1d(x, \"x\") if x is not None else self.x\n",
        "        z = self.Lm @ self.rng.standard_normal(self.p)\n",
        "        return self.H @ xk + z\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Advance one step and return (x_k, y_k).\"\"\"\n",
        "        xk = self.step_state()\n",
        "        yk = self.step_measurement(xk)\n",
        "        return xk, yk\n",
        "\n",
        "    def simulate(self, T):\n",
        "        \"\"\"Run T steps; returns X (T,n) and Y (T,p).\"\"\"\n",
        "        X = np.zeros((T, self.n))\n",
        "        Y = np.zeros((T, self.p))\n",
        "        for k in range(T):\n",
        "            X[k], Y[k] = self.step()\n",
        "        return X, Y\n",
        "\n",
        "    # ---------- helpers ----------\n",
        "    @staticmethod\n",
        "    def _as_2d(M, name):\n",
        "        M = np.asarray(M, dtype=float)\n",
        "        if M.ndim != 2:\n",
        "            raise LDSShapeError(f\"`{name}` must be 2D; got shape {M.shape}.\")\n",
        "        return M\n",
        "\n",
        "    @staticmethod\n",
        "    def _as_1d(v, name):\n",
        "        v = np.asarray(v, dtype=float)\n",
        "        if v.ndim == 2 and v.shape[1] == 1:\n",
        "            v = v[:, 0]\n",
        "        if v.ndim != 1:\n",
        "            raise LDSShapeError(f\"`{name}` must be 1D; got shape {v.shape}.\")\n",
        "        return v\n",
        "\n",
        "    @staticmethod\n",
        "    def _assert_symmetric(M, name, atol=1e-12):\n",
        "        if M.shape[0] != M.shape[1]:\n",
        "            raise LDSShapeError(f\"`{name}` must be square; got {M.shape}.\")\n",
        "        if not np.allclose(M, M.T, atol=atol):\n",
        "            raise LDSValueError(f\"`{name}` must be symmetric within atol={atol}.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _assert_spd(M, name):\n",
        "        try:\n",
        "            return np.linalg.cholesky(M)\n",
        "        except np.linalg.LinAlgError as e:\n",
        "            raise LDSValueError(f\"`{name}` must be symmetric positive definite (SPD). Cholesky failed: {e}\")\n",
        "\n",
        "    def animate_measurement_gaussians_scalar(\n",
        "        self,\n",
        "        *,\n",
        "        T: int | None = None,\n",
        "        Y: np.ndarray | None = None,\n",
        "        m0: np.ndarray | None = None,\n",
        "        P0: np.ndarray | None = None,\n",
        "        kf=None,\n",
        "        frame_ms: int = 120,\n",
        "        auto_play: bool = False,\n",
        "        save_html_path: str | None = None,\n",
        "        show: bool = True,\n",
        "        return_fig: bool = False,\n",
        "        component_label: str = \"y\"\n",
        "    ):\n",
        "        if self.p != 1:\n",
        "            raise ValueError(f\"This animation requires scalar measurements (p=1); got p={self.p}.\")\n",
        "\n",
        "        A = np.asarray(self.A, float)\n",
        "        H = np.asarray(self.H, float).reshape(1, -1)    # (1,n)\n",
        "        Q = np.asarray(self.Sigma_p, float)\n",
        "        Rm = np.asarray(self.Sigma_m, float)\n",
        "        R_scalar = float(np.atleast_2d(Rm)[0, 0])       # already a Python float\n",
        "\n",
        "        n = self.n\n",
        "\n",
        "        if Y is None:\n",
        "            if T is None:\n",
        "                raise ValueError(\"Provide either Y or T.\")\n",
        "            _, Y_sim = self.simulate(T)\n",
        "            Y = np.asarray(Y_sim, float).reshape(-1)\n",
        "        else:\n",
        "            Y = np.asarray(Y, float).reshape(-1)\n",
        "            T = Y.shape[0]\n",
        "\n",
        "        m = np.zeros(n) if m0 is None else np.asarray(m0, float).reshape(-1)\n",
        "        if m.shape[0] != n:\n",
        "            raise ValueError(f\"`m0` must have length n={n}; got {m.shape}.\")\n",
        "        P = (1e2 * np.eye(n)) if P0 is None else np.asarray(P0, float)\n",
        "        if P.shape != (n, n):\n",
        "            raise ValueError(f\"`P0` must be (n,n)=({n},{n}); got {P.shape}.\")\n",
        "\n",
        "        if kf is None:\n",
        "            kf = LinearKF(use_joseph=True, symmetrize=True)\n",
        "\n",
        "        mu_pred = np.zeros(T)\n",
        "        sig_pred = np.zeros(T)\n",
        "        mu_post = np.zeros(T)\n",
        "        sig_post = np.zeros(T)\n",
        "\n",
        "        for k in range(T):\n",
        "            # Predict\n",
        "            m_pred = A @ m\n",
        "            P_pred = A @ P @ A.T + Q\n",
        "\n",
        "            # Predictive y ~ N(H m^-, H P^- H^T + R)\n",
        "            mu_pred[k] = (H @ m_pred).item()                      # <-- .item()\n",
        "            S_pred = (H @ P_pred @ H.T).item() + R_scalar         # <-- .item()\n",
        "            sig_pred[k] = float(np.sqrt(S_pred)) if S_pred > 0 else 0.0\n",
        "\n",
        "            # Update with robust KF\n",
        "            m, P, _, _ = kf.measurement_update(m_pred, P_pred, H, np.array([Y[k]]), np.array([[R_scalar]]))\n",
        "\n",
        "            # Posterior-predictive y ~ N(H m, H P H^T + R)\n",
        "            mu_post[k] = (H @ m).item()                           # <-- .item()\n",
        "            S_post = (H @ P @ H.T).item() + R_scalar              # <-- .item()\n",
        "            sig_post[k] = float(np.sqrt(S_post)) if S_post > 0 else 0.0\n",
        "\n",
        "        # ---- plotting (unchanged except uses mu_* / sig_* arrays) ----\n",
        "        def _gauss_pdf(x, mu, sigma):\n",
        "            if sigma <= 0:\n",
        "                return np.zeros_like(x)\n",
        "            return (1.0 / (np.sqrt(2.0*np.pi) * sigma)) * np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
        "\n",
        "        pred_lo = np.min(mu_pred - 4.0 * sig_pred)\n",
        "        pred_hi = np.max(mu_pred + 4.0 * sig_pred)\n",
        "        post_lo = np.min(mu_post - 4.0 * sig_post)\n",
        "        post_hi = np.max(mu_post + 4.0 * sig_post)\n",
        "        y_lo = float(np.min(Y)) - 1e-6\n",
        "        y_hi = float(np.max(Y)) + 1e-6\n",
        "\n",
        "        x_min = float(np.min([pred_lo, post_lo, y_lo]))\n",
        "        x_max = float(np.max([pred_hi, post_hi, y_hi]))\n",
        "        if not np.isfinite(x_min) or not np.isfinite(x_max) or x_max <= x_min:\n",
        "            x_min, x_max = -3.0, 3.0\n",
        "\n",
        "        xgrid = np.linspace(x_min, x_max, 700)\n",
        "\n",
        "        frames = []\n",
        "        for k in range(T):\n",
        "            y_pred_pdf = _gauss_pdf(xgrid, mu_pred[k], sig_pred[k])\n",
        "            y_post_pdf = _gauss_pdf(xgrid, mu_post[k], sig_post[k])\n",
        "            ymax = float(max(y_pred_pdf.max(initial=0.0), y_post_pdf.max(initial=0.0)))\n",
        "\n",
        "            frames.append(\n",
        "                go.Frame(\n",
        "                    name=str(k),\n",
        "                    data=[\n",
        "                        go.Scatter(x=xgrid, y=y_pred_pdf, mode=\"lines\",\n",
        "                                name=\"Predictive p(y_k|Y_{k-1})\", showlegend=False),\n",
        "                        go.Scatter(x=xgrid, y=y_post_pdf, mode=\"lines\",\n",
        "                                name=\"Posterior p(y_k|Y_k)\", showlegend=False),\n",
        "                        go.Scatter(x=[Y[k]], y=[ymax*0.9], mode=\"markers\",\n",
        "                                name=f\"observed {component_label}_k\", showlegend=False, marker=dict(size=8)),\n",
        "                    ],\n",
        "                    layout=go.Layout(\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                x=0.98, y=0.95, xref=\"paper\", yref=\"paper\",\n",
        "                                xanchor=\"right\", yanchor=\"top\",\n",
        "                                text=(f\"k={k} | μ⁻={mu_pred[k]:.3f}, σ⁻={sig_pred[k]:.3f} \"\n",
        "                                    f\"| μ={mu_post[k]:.3f}, σ={sig_post[k]:.3f}\"),\n",
        "                                showarrow=False, font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "\n",
        "        y_pred_pdf0 = _gauss_pdf(xgrid, mu_pred[0], sig_pred[0])\n",
        "        y_post_pdf0 = _gauss_pdf(xgrid, mu_post[0], sig_post[0])\n",
        "        ymax0 = float(max(y_pred_pdf0.max(initial=0.0), y_post_pdf0.max(initial=0.0)))\n",
        "\n",
        "        fig = go.Figure(\n",
        "            data=[\n",
        "                go.Scatter(x=xgrid, y=y_pred_pdf0, mode=\"lines\", name=\"Predictive p(y_k|Y_{k-1})\"),\n",
        "                go.Scatter(x=xgrid, y=y_post_pdf0, mode=\"lines\", name=\"Posterior p(y_k|Y_k)\"),\n",
        "                go.Scatter(x=[Y[0]], y=[ymax0*0.9], mode=\"markers\",\n",
        "                        name=f\"observed {component_label}_k\", marker=dict(size=8)),\n",
        "            ],\n",
        "            layout=go.Layout(\n",
        "                title=\"Scalar KF: Predictive vs Posterior-Predictive Measurement Gaussians\",\n",
        "                xaxis_title=component_label,\n",
        "                yaxis_title=\"density\",\n",
        "                template=\"plotly_white\",\n",
        "                legend=dict(orientation=\"v\", x=1.02, xanchor=\"left\", y=0.5, yanchor=\"middle\"),\n",
        "                margin=dict(r=160, l=60, t=60, b=80),\n",
        "                updatemenus=[\n",
        "                    dict(\n",
        "                        type=\"buttons\", direction=\"left\",\n",
        "                        x=0.0, y=1.15, xanchor=\"left\", yanchor=\"top\",\n",
        "                        buttons=[\n",
        "                            dict(label=\"Play\", method=\"animate\",\n",
        "                                args=[None, {\"frame\": {\"duration\": frame_ms, \"redraw\": True},\n",
        "                                            \"transition\": {\"duration\": 0},\n",
        "                                            \"fromcurrent\": True}]),\n",
        "                            dict(label=\"Pause\", method=\"animate\",\n",
        "                                args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
        "                                                \"mode\": \"immediate\",\n",
        "                                                \"transition\": {\"duration\": 0}}]),\n",
        "                        ],\n",
        "                    )\n",
        "                ],\n",
        "                sliders=[\n",
        "                    dict(\n",
        "                        active=0, x=0.05, y=-0.12, xanchor=\"left\", yanchor=\"top\",\n",
        "                        len=0.9,\n",
        "                        currentvalue=dict(prefix=\"k = \", visible=True, xanchor=\"right\"),\n",
        "                        steps=[dict(method=\"animate\",\n",
        "                                    args=[[str(k)], {\"mode\": \"immediate\",\n",
        "                                                    \"frame\": {\"duration\": 0, \"redraw\": True},\n",
        "                                                    \"transition\": {\"duration\": 0}}],\n",
        "                                    label=str(k)) for k in range(T)]\n",
        "                    )\n",
        "                ],\n",
        "            ),\n",
        "            frames=frames\n",
        "        )\n",
        "\n",
        "        if save_html_path:\n",
        "            fig.write_html(save_html_path, include_plotlyjs=\"cdn\", auto_play=auto_play)\n",
        "\n",
        "        if show:\n",
        "            fig.show()\n",
        "        if return_fig:\n",
        "            return fig\n",
        "\n",
        "    def plot_y(self, Y, *, nbins=40, component_labels=None,\n",
        "                        curve_samples=500, show=True, return_fig=False):\n",
        "        \"\"\"\n",
        "        Plot all measurement components y[:, j] together in one figure as scatter traces.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Y : array_like, shape (T, p)\n",
        "            Collected measurements over T steps.\n",
        "        nbins, curve_samples : kept for API compatibility (not used).\n",
        "        component_labels : list[str] | None\n",
        "            Optional labels per y-dimension; defaults to ['y[0]', ..., 'y[p-1]'].\n",
        "        show : bool, default True\n",
        "            Call fig.show().\n",
        "        return_fig : bool, default False\n",
        "            If True, return the plotly Figure.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        fig : plotly.graph_objects.Figure (only if return_fig=True)\n",
        "        \"\"\"\n",
        "        Y = np.asarray(Y, dtype=float)\n",
        "        if Y.ndim != 2:\n",
        "            raise LDSShapeError(f\"`Y` must be 2D with shape (T, p); got {Y.shape}.\")\n",
        "        T, p = Y.shape\n",
        "        if p != self.p:\n",
        "            raise LDSShapeError(f\"`Y` second dim (p={p}) must match system p={self.p}.\")\n",
        "\n",
        "        labels = component_labels or [f\"y[{j}]\" for j in range(p)]\n",
        "        t = np.arange(T)\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        for j in range(p):\n",
        "            yj = Y[:, j]\n",
        "            mask = np.isfinite(yj)\n",
        "            if not np.any(mask):\n",
        "                # If a component has no finite points, annotate and skip\n",
        "                continue\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=t[mask], y=yj[mask],\n",
        "                    mode=\"lines+markers\",\n",
        "                    name=labels[j],\n",
        "                    marker=dict(size=5),\n",
        "                    line=dict(width=1),\n",
        "                    hovertemplate=\"k=%{x}<br>y=%{y:.4g}<extra>\" + labels[j] + \"</extra>\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"Measurement Traces (all y components)\",\n",
        "            template=\"plotly_white\",\n",
        "            height=420 if p <= 3 else 480,\n",
        "            legend=dict(\n",
        "                orientation=\"v\",\n",
        "                x=1.02, xanchor=\"left\",\n",
        "                y=0.5,  yanchor=\"middle\",\n",
        "            ),\n",
        "            margin=dict(r=160),\n",
        "        )\n",
        "        fig.update_xaxes(title_text=\"time step (k)\")\n",
        "        fig.update_yaxes(title_text=\"y components\")\n",
        "\n",
        "        if show:\n",
        "            fig.show()\n",
        "        if return_fig:\n",
        "            return fig\n",
        "\n",
        "\n",
        "    def filter_with_kf_and_plot(\n",
        "        self,\n",
        "        *,\n",
        "        T: int | None = None,\n",
        "        Y: np.ndarray | None = None,\n",
        "        m0: np.ndarray | None = None,\n",
        "        P0: np.ndarray | None = None,\n",
        "        kf=None,  # instance of LinearKF; if None, a default LinearKF() is used\n",
        "        component_labels: list[str] | None = None,\n",
        "        nbins: int = 40,            # kept for signature compatibility (unused)\n",
        "        curve_samples: int = 500,\n",
        "        show: bool = True,\n",
        "        return_fig: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Run a Kalman filter over provided (or simulated) measurements and plot:\n",
        "          (1) y_k (noisy) vs filtered estimate H m_k  [time series]\n",
        "          (2) residual Gaussians ONLY (no histograms):\n",
        "              - Gaussian Approx. (MLE mu/sigma from residuals e_k = y_k - H m_k)\n",
        "              - Modeled Noise Gaussian N(0, diag(Sigma_m))\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        M : ndarray, shape (T, n)\n",
        "            Filtered means m_k for k=1..T.\n",
        "        Yhat : ndarray, shape (T, p)\n",
        "            Filtered measurement estimates H m_k.\n",
        "        (fig_ts, fig_gauss) : Figures if return_fig=True\n",
        "        \"\"\"\n",
        "        # ----- validate / prepare inputs -----\n",
        "        A = np.asarray(self.A, float)\n",
        "        H = np.asarray(self.H, float)\n",
        "        Q = np.asarray(self.Sigma_p, float)\n",
        "        R = np.asarray(self.Sigma_m, float)\n",
        "        n, p = self.n, self.p\n",
        "\n",
        "        if Y is None:\n",
        "            if T is None:\n",
        "                raise ValueError(\"Provide either Y or T.\")\n",
        "            _, Y = self.simulate(T)\n",
        "        else:\n",
        "            Y = np.asarray(Y, float)\n",
        "            if Y.ndim != 2 or Y.shape[1] != p:\n",
        "                raise ValueError(f\"`Y` must have shape (T, p={p}); got {Y.shape}.\")\n",
        "            T = Y.shape[0]\n",
        "\n",
        "        m = np.zeros(n) if m0 is None else np.asarray(m0, float).reshape(-1)\n",
        "        if m.shape[0] != n:\n",
        "            raise ValueError(f\"`m0` must have length n={n}; got {m.shape}.\")\n",
        "        P = (1e2 * np.eye(n)) if P0 is None else np.asarray(P0, float)\n",
        "        if P.shape != (n, n):\n",
        "            raise ValueError(f\"`P0` must be shape (n,n)=({n},{n}); got {P.shape}.\")\n",
        "\n",
        "        if kf is None:\n",
        "            kf = LinearKF(use_joseph=True, symmetrize=True)\n",
        "\n",
        "        # ----- filtering loop -----\n",
        "        M = np.zeros((T, n))\n",
        "        Yhat = np.zeros((T, p))\n",
        "\n",
        "        for k in range(T):\n",
        "            # Predict\n",
        "            m_pred = A @ m\n",
        "            P_pred = A @ P @ A.T + Q\n",
        "\n",
        "            # Update\n",
        "            m, P, _, _ = kf.measurement_update(m_pred, P_pred, H, Y[k], R)\n",
        "\n",
        "            # Store\n",
        "            M[k] = m\n",
        "            Yhat[k] = H @ m\n",
        "\n",
        "        # Residuals (posterior): e_k = y_k - H m_k\n",
        "        E = Y - Yhat  # shape (T, p)\n",
        "\n",
        "        # ----- plot (1): time series y vs Hm -----\n",
        "        labels = component_labels or [f\"y[{j}]\" for j in range(p)]\n",
        "        t = np.arange(T)\n",
        "        fig_ts = make_subplots(rows=p, cols=1, shared_xaxes=True,\n",
        "                               subplot_titles=[f\"{lab}: noisy vs filtered Hm\" for lab in labels])\n",
        "\n",
        "        for j in range(p):\n",
        "            fig_ts.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=t, y=Y[:, j],\n",
        "                    mode=\"markers\",\n",
        "                    name=f\"{labels[j]} noisy\",\n",
        "                    marker=dict(size=5),\n",
        "                ),\n",
        "                row=j+1, col=1\n",
        "            )\n",
        "            fig_ts.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=t, y=Yhat[:, j],\n",
        "                    mode=\"lines\",\n",
        "                    name=f\"{labels[j]} filtered (H m)\",\n",
        "                ),\n",
        "                row=j+1, col=1\n",
        "            )\n",
        "            fig_ts.update_yaxes(title_text=labels[j], row=j+1, col=1)\n",
        "\n",
        "        fig_ts.update_xaxes(title_text=\"time step\", row=p, col=1)\n",
        "        fig_ts.update_layout(\n",
        "            title=\"Measurements vs. KF Filtered Estimates (H m_k)\",\n",
        "            template=\"plotly_white\",\n",
        "            height=max(300, 260 * p),\n",
        "            legend=dict(\n",
        "                orientation=\"v\",\n",
        "                x=1.02, xanchor=\"left\",\n",
        "                y=0.5,  yanchor=\"middle\",\n",
        "            ),\n",
        "            margin=dict(r=140),\n",
        "        )\n",
        "\n",
        "        # ----- plot (2): residual Gaussians only -----\n",
        "        def _gauss_pdf(x, mu, sigma):\n",
        "            if sigma <= 0:\n",
        "                return np.zeros_like(x)\n",
        "            return (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
        "\n",
        "        fig_gauss = make_subplots(\n",
        "            rows=p, cols=1, shared_xaxes=False,\n",
        "            subplot_titles=[f\"{lab} residual Gaussian fits\" for lab in labels]\n",
        "        )\n",
        "\n",
        "        for j in range(p):\n",
        "            ej_raw = E[:, j]\n",
        "            ej = ej_raw[np.isfinite(ej_raw)]\n",
        "            # Sample-based parameters (MLE)\n",
        "            mu_hat = float(np.mean(ej)) if ej.size else 0.0\n",
        "            sigma_hat = float(np.std(ej, ddof=0)) if ej.size else 0.0\n",
        "            # Modeled marginal std from R (diagonal)\n",
        "            sigma_model = float(np.sqrt(max(R[j, j], 0.0)))\n",
        "\n",
        "            # x-range covering both curves; ensure a minimum width\n",
        "            span = max(1e-6, 4.0 * sigma_hat, 4.0 * sigma_model, np.ptp(ej) if ej.size > 1 else 0.0)\n",
        "            center = mu_hat\n",
        "            lo = center - 0.5 * span\n",
        "            hi = center + 0.5 * span\n",
        "            if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
        "                lo, hi = -1.0, 1.0\n",
        "\n",
        "            xgrid = np.linspace(lo, hi, curve_samples)\n",
        "            pdf_hat = _gauss_pdf(xgrid, mu_hat, sigma_hat)\n",
        "            pdf_model = _gauss_pdf(xgrid, 0.0, sigma_model)\n",
        "\n",
        "            fig_gauss.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=xgrid, y=pdf_hat,\n",
        "                    mode=\"lines\",\n",
        "                    name=f\"{labels[j]} Gaussian Approx (μ̂={mu_hat:.3g}, σ̂={sigma_hat:.3g})\",\n",
        "                    hovertemplate=\"x=%{x:.4g}<br>pdf=%{y:.4g}<extra></extra>\",\n",
        "                ),\n",
        "                row=j+1, col=1\n",
        "            )\n",
        "            fig_gauss.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=xgrid, y=pdf_model,\n",
        "                    mode=\"lines\",\n",
        "                    name=f\"{labels[j]} Modeled N(0, R_jj) (σ={sigma_model:.3g})\",\n",
        "                    hovertemplate=\"x=%{x:.4g}<br>pdf=%{y:.4g}<extra></extra>\",\n",
        "                ),\n",
        "                row=j+1, col=1\n",
        "            )\n",
        "\n",
        "            fig_gauss.update_xaxes(title_text=f\"{labels[j]} residual e = y - Hm\", row=j+1, col=1)\n",
        "            fig_gauss.update_yaxes(title_text=\"density\", row=j+1, col=1)\n",
        "\n",
        "        fig_gauss.update_layout(\n",
        "            title=\"Residual Gaussian Fits (Sample MLE vs. Modeled Noise)\",\n",
        "            template=\"plotly_white\",\n",
        "            height=max(300, 260 * p),\n",
        "            legend=dict(\n",
        "                orientation=\"v\",\n",
        "                x=1.02, xanchor=\"left\",\n",
        "                y=0.5,  yanchor=\"middle\",\n",
        "            ),\n",
        "            margin=dict(r=240),\n",
        "        )\n",
        "\n",
        "        if show:\n",
        "            fig_ts.show()\n",
        "            fig_gauss.show()\n",
        "\n",
        "        return (M, Yhat, fig_ts, fig_gauss) if return_fig else (M, Yhat)"
      ],
      "metadata": {
        "id": "X0NJrYue1RaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D position-only measurements (p=2), CV model in x & y\n",
        "def make_cv2d(dt=0.1, q=1e-2, r=0.5, x0=(0,0, 1,0.5), seed=0):\n",
        "    A = np.array([\n",
        "        [1, 0, dt,  0],\n",
        "        [0, 1,  0, dt],\n",
        "        [0, 0,  1,  0],\n",
        "        [0, 0,  0,  1],\n",
        "    ])\n",
        "    # Measure x and y only\n",
        "    H = np.array([\n",
        "        [1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "    ])\n",
        "    Q_block = np.array([[dt**3/3, dt**2/2],\n",
        "                        [dt**2/2, dt      ]]) * q\n",
        "    Q = np.block([\n",
        "        [Q_block,         np.zeros((2,2))],\n",
        "        [np.zeros((2,2)), Q_block        ]\n",
        "    ])\n",
        "    R = np.eye(2) * (r**2)\n",
        "    return LinearGaussianSystemSyms(A=A, H=H, Sigma_p=Q, Sigma_m=R,\n",
        "                                x0=np.asarray(x0, float), rng=np.random.default_rng(seed))\n"
      ],
      "metadata": {
        "id": "8LmAW1Mu1Zpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys = make_cv2d(dt=0.1, q=1e-2, r=0.5, x0=(0,0, 0.5, -0.2), seed=7)\n",
        "X2, Y2 = sys.simulate(T=300)\n",
        "sys.plot_y(Y2, nbins=40, component_labels=[\"pos_x\", \"pos_y\"])"
      ],
      "metadata": {
        "id": "TnSD7mkF7bs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: simulate 300 steps internally, starting from broad prior\n",
        "M, Yhat= sys.filter_with_kf_and_plot(T=300, m0=np.array([0,0, 0,0]), P0=np.eye(4)*100,\n",
        "                                      component_labels=[\"pos_x\",\"pos_y\"], show=True)\n",
        "\n",
        "# Option B: if you already have measurements Y, just pass them:\n",
        "# X, Y = sys.simulate(T=300)\n",
        "# M, Yhat = sys.filter_with_kf_and_plot(Y=Y, m0=np.array([0,0, 0,0]), P0=np.eye(4)*100,\n",
        "#                                       component_labels=[\"pos_x\",\"pos_y\"])"
      ],
      "metadata": {
        "id": "XGiqFeHT6K0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmjkVkU_KRj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_1.show()"
      ],
      "metadata": {
        "id": "Zvh45U7LATzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_upd"
      ],
      "metadata": {
        "id": "n0omFqgKzPqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New"
      ],
      "metadata": {
        "id": "VV5RTSCwuEB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Kalman Filter on $\\mathbb{R}^n$"
      ],
      "metadata": {
        "id": "6oFzSDDmlQUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a system modelled by a Markov process\n",
        "\\begin{align}\n",
        "x_k &= A_k\\,x_{k-1} + G_k\\,w_{k-1}, \\qquad\\\\\n",
        "y_k & = H_k\\,x_k + z_k. \\qquad\n",
        "\\end{align}\n",
        "We assume $p(w_k)=\\mathscr{N}(0,\\Sigma_p)$ and $p(z_k)=\\mathscr{N}(0,\\Sigma_m)$, where $\\mathscr{N}(\\mu,\\Sigma)$ denotes a multivariate Gaussian with mean $\\mu$ and covariance $\\Sigma$.\n",
        "\n",
        "Let $Y_k$ denote the event corresponding to a realization of $\\{y_1,\\dots,y_k\\}$. Define\n",
        "\\begin{align}\n",
        "\\widehat{x}_k^+ &\\triangleq x_k|Y_k,\\qquad\\\\\n",
        "\\widehat{x}_k^- &\\triangleq x_k|Y_{k-1},\\qquad\\\\\n",
        "y_k^- &\\triangleq y_k|Y_{k-1}.\\\\\n",
        "\\end{align}\n",
        "Assume the model\n",
        "\\begin{align}\n",
        "\\widehat{x}_k^- &= A_k\\,x_{k-1}^+ + G_{k-1}\\,w_{k-1}, \\qquad\\\\\n",
        "y_k^- &= H_k\\,\\widehat{x}_k^- + z_k. \\qquad\n",
        "\\end{align}\n",
        "If $p(x_0^-)=\\mathscr{N}(m_0,P_0)$, then since $p(w_k)=\\mathscr{N}(0,\\Sigma_p)$, the linear system above implies\n",
        "$p(x_k|Y_{k-1})=p(\\widehat{x}_k^-)=\\mathscr{N}(m_k^-,P_k^-)$,\n",
        "with predicted mean and covariance\n",
        "\\begin{align}\n",
        "m_k^- &= A_k\\,m_{k-1}, \\qquad\\\\\n",
        "P_k^- &= A_k\\,P_{k-1}\\,A_k^{T} + G_k\\,\\Sigma_p\\,G_k^{T}. \\qquad\n",
        "\\end{align}\n",
        "Here $p(x_k|Y_k)=p(\\widehat{x}_k^+)=\\mathscr{N}(m_k,P_k)$.  ￼\n",
        "\n",
        "Furthermore, since $p(z_k)=\\mathscr{N}(0,\\Sigma_m)$ we have,\n",
        "\\begin{align}\n",
        "p(y_k|Y_{k-1})=\\mathscr{N}\\big(H_k m_k^-,\\; H_k P_k^- H_k^{T}+\\Sigma_m\\big),\n",
        "\\end{align}\n",
        "so the joint distribution is\n",
        "\\begin{align}\n",
        "p\n",
        "\\begin{pmatrix}x_k|Y_{k-1}\\\\[2pt] y_k|Y_{k-1}\\end{pmatrix}\n",
        "=\n",
        "\\mathscr{N}\\left(\n",
        "\\begin{bmatrix}\n",
        "m_k^- \\\\\n",
        "H_k m_k^-\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "P_k^- & P_k^- H_k^{\\!T} \\\\\n",
        "H_k P_k^- & H_k P_k^- H_k^{\\!T} + \\Sigma_m\n",
        "\\end{bmatrix}\n",
        "\\right).\n",
        "\\end{align}\n",
        "Then from the properties of multivariate normals, the conditional distribution $p(x_k|Y_k)$ is\n",
        "\\begin{align}\n",
        "p(x_k|Y_k)=\\mathscr{N}\\Big(\n",
        "m_k^- + P_k^- H_k^{\\!T}\\!\\big(H_k P_k^- H_k^{\\!T}+\\Sigma_m\\big)^{-1}\\!(y_k - H_k m_k^-),\\;\n",
        "P_k^- - P_k^- H_k^{\\!T}\\!\\big(H_k P_k^- H_k^{\\!T}+\\Sigma_m\\big)^{-1}\\!H_k P_k^-\n",
        "\\Big). \\quad\n",
        "\\end{align}\n",
        "\n",
        "Thus the updated mean and covariance are\n",
        "\\begin{align}\n",
        "K_k &\\triangleq P_k^- H_k^{\\!T}\\!\\big(H_k P_k^- H_k^{\\!T}+\\Sigma_m\\big)^{-1}, \\qquad \\\\\n",
        "m_k &= m_k^- + K_k\\,(y_k - H_k m_k^-), \\qquad \\\\\n",
        "P_k &= (I - K_k H_k)\\,P_k^-. \\qquad\n",
        "\\end{align}\n",
        "Here $\\Sigma_p = \\mathbb{E}(w_k w_k^{T})$ and $\\Sigma_m=\\mathbb{E}(z_k z_k^{T})$. Defining the estimation error $e_k \\triangleq x_k - m_k$, we have\n",
        "\\begin{align}\n",
        "e_k &= (I-K_k H_k) A_k e_{k-1} + (I-K_k H_k) w_{k-1} - K_k z_k,\\\\\n",
        "P_k &= (I-K_k H_k)\\big(A_k P_{k-1} A_k^{\\!T} + \\Sigma_p\\big).\n",
        "\\end{align}\n",
        "\n",
        "⸻\n",
        "\n"
      ],
      "metadata": {
        "id": "Pkq2EdvFlAGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-D Example"
      ],
      "metadata": {
        "id": "ewQ8JDxPIyFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let the scalar linear–Gaussian model be\n",
        "\\begin{aligned}\n",
        "x_k &= a\\,x_{k-1} + w_{k-1},\\qquad w_{k-1}\\sim\\mathscr N(0,q),\\\\\n",
        "y_k &= h\\,x_k + z_k,\\qquad\\;\\;\\;\\; z_k\\sim\\mathscr N(0,r),\n",
        "\\end{aligned}\n",
        "with prior $x_0\\sim \\mathscr{N}(m_0,P_0)$. Define $Y_{k-1}=\\{y_1,\\dots,y_{k-1}\\}$.\n",
        "\n",
        "Prediction:\n",
        "\n",
        "\\begin{aligned}\n",
        "m_k^- &= a\\,m_{k-1},\\\\[2pt]\n",
        "P_k^- &= a^2 P_{k-1} + q.\n",
        "\\end{aligned}\n",
        "\n",
        "Innovation (measurement) model and variance:\n",
        "\\begin{aligned}\n",
        "v_k &\\triangleq y_k - h\\,m_k^-,\\\\[2pt]\n",
        "S_k &= h^2 P_k^- + r.\n",
        "\\end{aligned}\n",
        "\n",
        "Kalman gain:\n",
        "\\begin{align}\n",
        "K_k = \\dfrac{P_k^-\\,h}{S_k}.\n",
        "\\end{align}\n",
        "\n",
        "Update:\n",
        "\\begin{aligned}\n",
        "m_k &= m_k^- + K_k\\,v_k\n",
        "= m_k^- + \\frac{P_k^- h}{S_k}\\bigl(y_k - h\\,m_k^-\\bigr),\\\\[6pt]\n",
        "P_k &= (1 - K_k h)\\,P_k^-\n",
        "= \\Bigl(1 - \\frac{P_k^- h^2}{S_k}\\Bigr) P_k^- .\n",
        "\\end{aligned}\n",
        "\n",
        "Predictive measurement distribution (before seeing y_k):\n",
        "\\begin{align}\n",
        "p(y_k | Y_{k-1})=\\mathscr N\\bigl(h\\,m_k^-,\\; h^2 P_k^- + r\\bigr).\n",
        "\\end{align}\n",
        "\n",
        "Posterior-predictive measurement distribution (after filtering on y_k):\n",
        "\\begin{align}\n",
        "p(y_k\\mid Y_k)=\\mathscr N\\bigl(h\\,m_k,\\; h^2 P_k + r\\bigr).\n",
        "\\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "fD8rDxlhIpnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_cv1d(dt: float = 0.1,\n",
        "              q: float = 1e-2,\n",
        "              r: float = 1e-1,\n",
        "              x0=(0.0, 1.0),\n",
        "              seed: int | None = None) -> LinearGaussianSystemSyms:\n",
        "    \"\"\"\n",
        "    Build a 1D constant-velocity linear Gaussian system:\n",
        "\n",
        "        x_k = A x_{k-1} + w_{k-1},      w ~ N(0, Q)\n",
        "        y_k = H x_k       + z_k,        z ~ N(0, R)\n",
        "\n",
        "    State: x = [position, velocity]^T  (n=2)\n",
        "    Measurement: y = position (scalar, p=1)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dt : float\n",
        "        Sampling period Δt.\n",
        "    q : float\n",
        "        Continuous white-acceleration noise intensity (process noise scale).\n",
        "        Discrete-time Q = q * [[dt^3/3, dt^2/2],\n",
        "                               [dt^2/2, dt     ]].\n",
        "    r : float\n",
        "        Measurement noise std. R = [[r^2]] (scalar variance).\n",
        "    x0 : tuple[float, float]\n",
        "        Initial state (position, velocity).\n",
        "    seed : int | None\n",
        "        Seed for reproducible randomness.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    LinearGaussianSystemSyms\n",
        "        System with A, H, Sigma_p (Q), Sigma_m (R), and initial state x0.\n",
        "    \"\"\"\n",
        "    A = np.array([[1.0, dt],\n",
        "                  [0.0, 1.0]], dtype=float)\n",
        "\n",
        "    # Measure position only (scalar)\n",
        "    H = np.array([[1.0, 0.0]], dtype=float)  # shape (1,2)\n",
        "\n",
        "    # Discrete CV process noise covariance (from white-acceleration model)\n",
        "    Q = q * np.array([[dt**3/3.0, dt**2/2.0],\n",
        "                      [dt**2/2.0, dt      ]], dtype=float)\n",
        "\n",
        "    # Measurement noise covariance (scalar)\n",
        "    R = np.array([[r**2]], dtype=float)\n",
        "\n",
        "    x0 = np.asarray(x0, dtype=float)\n",
        "    if x0.shape != (2,):\n",
        "        raise ValueError(f\"`x0` must be shape (2,), got {x0.shape}.\")\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    return LinearGaussianSystemSyms(A=A, H=H, Sigma_p=Q, Sigma_m=R, x0=x0, rng=rng)\n",
        "\n",
        "# Must have p=1 in your system (scalar measurement). n can be >1.\n",
        "sys = make_cv1d(dt=0.1, q=5e-2, r=1.0, x0=(0.0, 0.5), seed=7)  # p=1\n",
        "# Run with simulated Y (T provided)\n",
        "sys.animate_measurement_gaussians_scalar(T=80, m0=np.zeros(sys.n), P0=np.eye(sys.n)*100,\n",
        "                                         frame_ms=120, save_html_path=None, show=True)\n",
        "\n",
        "# Or if you've already collected Y (shape (T,) or (T,1)):\n",
        "# _, Y = sys.simulate(T=100)\n",
        "# sys.animate_measurement_gaussians_scalar(Y=Y, m0=np.zeros(sys.n), P0=np.eye(sys.n)*100,\n",
        "#                                          save_html_path=\"kf_scalar_y_gaussians.html\", auto_play=False)"
      ],
      "metadata": {
        "id": "5qiffju6qWEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DISCRETE TIME PRE-OBSERVERS ON LIE GROUPS WITH TIME INVARIANT ERROR DYNAMICS"
      ],
      "metadata": {
        "id": "UaUiYuhCsBlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let $G$ be an $n$-dimensional Lie group with Lie algebra $G$. Let $(g,\\zeta)\\in G\\times G$ and let $\\phi:G\\times M\\to M$ be a left- or right-invariant action on an $m$-dimensional manifold $M$. We consider the kinematic system\n",
        "\\begin{align}\n",
        "\\dot g &= g\\cdot \\zeta,  \\tag{1}\\\\\n",
        "y &= \\phi_g(\\gamma), \\tag{2}\n",
        "\\end{align}\n",
        "where $\\zeta(t)\\in G$ is a known input and $\\gamma\\in M$ is a known constant. A standard discrete-time approximation is\n",
        "\\begin{align}\n",
        "g_k &= g_{k-1},\\exp(\\Delta T,\\zeta_{k-1}), \\tag{3}\n",
        "\\end{align}\n",
        "with sampling period $\\Delta T$. (This discretization is classical.)\n",
        "\n"
      ],
      "metadata": {
        "id": "3sW8LMmErCnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For left-invariant outputs"
      ],
      "metadata": {
        "id": "PnzheVgHsylz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the pre-observer\n",
        "\\begin{align}\n",
        "\\tilde g_k^- &= \\tilde g_{k-1},\\exp(\\Delta T,\\zeta_{k-1}), \\tag{4}\\\\\n",
        "\\tilde g_k &= \\tilde g_k^-,\\exp!\\big(\\Delta T,L(y_k,\\tilde y_k)\\big), \\tag{5}\\\\\n",
        "\\tilde y_k &= \\phi_{\\tilde g_k}(\\gamma), \\tag{6}\n",
        "\\end{align}\n",
        "where $L:M\\times M\\to G$ is the innovation term. Define $u_k\\triangleq \\exp(\\Delta T,\\zeta_{k-1})$, the a priori error $e_k^-\\triangleq (\\tilde g_k^-)^{-1}g_k$, and the a posteriori error $e_k\\triangleq \\tilde g_k^{-1}g_k$. Then\n",
        "\\begin{align}\n",
        "e_k^- &= (\\tilde g_k^-)^{-1} g_k ;=; u_{k-1}^{-1},\\tilde g_{k-1}^{-1} g_{k-1},u_{k-1}\n",
        ";=; u_{k-1}^{-1},e_{k-1},u_{k-1},\\\n",
        "e_k &= \\tilde g_k^{-1} g_k ;=; \\exp!\\big(-\\Delta T,L(y_k,\\tilde y_k)\\big),e_k^-.\n",
        "\\end{align}\n",
        "If $L$ is $G$-invariant, i.e., $L!\\big(\\phi_g(y_1),\\phi_g(y_2)\\big)=L(y_1,y_2)$ for all $g\\in G$, then using $y_k=\\phi_{g_k}(\\gamma)$ and $\\tilde y_k=\\phi_{\\tilde g_k}(\\gamma)$ one obtains $L(y_k,\\tilde y_k)=L\\big(\\phi_{e_k}(\\gamma),\\gamma\\big)$, so the error dynamics are autonomous (time invariant).\n",
        "\n"
      ],
      "metadata": {
        "id": "VL5W5HdNspRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For right-invariant outputs"
      ],
      "metadata": {
        "id": "0YU3xg1ztC98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the pre-observer\n",
        "\\begin{align}\n",
        "\\tilde g_k^- &= \\tilde g_{k-1},\\exp(\\Delta T,\\zeta_{k-1}), \\tag{7}\\\\\n",
        "\\tilde g_k &= \\exp!\\big(\\Delta T,L(y_k,\\tilde y_k)\\big),\\tilde g_k^-, \\tag{8}\\\\\n",
        "\\tilde y_k &= \\phi_{\\tilde g_k}(\\gamma). \\tag{9}\n",
        "\\end{align}\n",
        "With $u_k\\triangleq \\exp(\\Delta T,\\zeta_{k-1})$ and the right-invariant errors $e_k^-\\triangleq g_k(\\tilde g_k^-)^{-1}$ and $e_k\\triangleq g_k\\tilde g_k^{-1}$, the error dynamics satisfy\n",
        "\\begin{align}\n",
        "e_k^- &= g_k(\\tilde g_k^-)^{-1} ;=; g_{k-1},u_{k-1},u_{k-1}^{-1},\\tilde g_{k-1}^{-1}\n",
        ";=; e_{k-1},\\\\\n",
        "e_k &= g_k\\tilde g_k^{-1} ;=; e_k^-,\\exp!\\big(-\\Delta T,L(y_k,\\tilde y_k)\\big).\n",
        "\\end{align}\n",
        "If $L$ is $G$-invariant, one similarly gets $L(y_k,\\tilde y_k)=L\\big(\\phi_{e_k}(\\gamma),\\gamma\\big)$, hence the error dynamics are autonomous.\n",
        "\n"
      ],
      "metadata": {
        "id": "SXEecNQGssay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The IMU+GNSS sensor fusion problem"
      ],
      "metadata": {
        "id": "pv16-uuXtW6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A representative application is rigid-body orientation/pose estimation with IMU and GNSS. Gyroscopes measure body-frame angular velocity $\\Omega$, accelerometers measure $A_m$ (specific force), and GNSS provides $o,\\dot o$. A convenient reformulation introduces\n",
        "\\begin{align}\n",
        "o_s(t)&\\triangleq o(t)+\\tfrac{1}{2}gt^2 e_3,\\qquad\\\\\n",
        "v_s(t)&\\triangleq \\dot o_s(t)=\\dot o(t)+g t\\,e_3,\\qquad\\\\\n",
        "R\\,A_m&=\\ddot o_s(t)=\\ddot o(t)+g e_3,\n",
        "\\end{align}\n",
        "giving the continuous-time model\n",
        "\\begin{align}\n",
        "\\dot R &= R,\\widehat\\Omega, \\tag{21}\\\\\n",
        "\\dot v_s &= R,A_m, \\tag{22}\\\\\n",
        "\\dot o_s &= v_s, \\tag{23}\\\\\n",
        "y_o &= o_s, \\tag{24}\\\\\n",
        "y_v &= v_s. \\tag{25}\n",
        "\\end{align}\n",
        "Defining the homogeneous state\n",
        "\\begin{align}\n",
        "X &\\triangleq\\;\n",
        "\\begin{bmatrix}\n",
        "R & v_s\\\\[2pt]\n",
        "0 & 1\n",
        "\\end{bmatrix},\\qquad\\\\\n",
        "\\zeta &\\triangleq\n",
        "\\begin{bmatrix}\n",
        "\\widehat\\Omega & A_m\\\\[2pt]\n",
        "0 & 0\n",
        "\\end{bmatrix},\\qquad\\\\\n",
        "\\gamma_v &\\triangleq\\;\n",
        "\\begin{bmatrix}\n",
        "0_{3\\times 1}\\\\[2pt]\n",
        "1\n",
        "\\end{bmatrix},\n",
        "\\end{align}\n",
        "the dynamics/output compactly read\n",
        "\\begin{align}\n",
        "\\dot X &= X,\\zeta, \\tag{26}\\\\\n",
        "y_v &= X,\\gamma_v. \\tag{27}\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "PM7TZwYbtSq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "Nm-7c-B8lJXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] K. C. Wolfe, M. Mashner, and G. S. Chirikjian, “Bayesian fusion on Lie groups,” *Journal of Algebraic Statistics*, 2(1):75–97, 2011. [Link](https://rpk.lcsr.jhu.edu/publications/)\n",
        "\n",
        "[2] S. Bonnable, P. Martin, and E. Salan, “Invariant extended Kalman filter: theory and application to a velocity-aided attitude estimation problem,” *Proc. 48th IEEE CDC/28th CCC*, pp. 1297–1304, Dec 2009. [Link](https://doi.org/10.1109/CDC.2009.5399990)\n",
        "\n",
        "[3] S. Bonnabel, “Left-invariant extended Kalman filter and attitude estimation,” *Proc. 46th IEEE CDC*, pp. 1027–1032, Dec 2007. [Link](https://doi.org/10.1109/CDC.2007.4434662)\n",
        "\n",
        "[4] G. Bourmaud, R. Mégret, A. Giremus, and Y. Berthoumieu, “Discrete extended Kalman filter on Lie groups,” *EUSIPCO 2013*, pp. 1–5, Sept 2013. [Link](https://hal.science/hal-00903252/document)\n",
        "\n",
        "[5] G. S. Chirikjian, “Information theory on Lie groups and mobile robotics applications,” *Proc. 2010 IEEE ICRA*, pp. 2751–2757, May 2010. [Link](https://rpk.lcsr.jhu.edu/publications/)\n",
        "\n",
        "[6] Y. Wang and G. S. Chirikjian, “Error propagation on the Euclidean group with applications to manipulator kinematics,” *IEEE Trans. Robotics*, 22(4):591–602, Aug 2006. [Link](https://ieeexplore.ieee.org/document/1673946)\n",
        "\n",
        "[7] M. J. Piggott and V. Solo, “Stochastic numerical analysis for Brownian motion on SO(3),” *Proc. 53rd IEEE CDC*, pp. 3420–3425, Dec 2014. [Link](https://doi.org/10.1109/CDC.2014.7039919)\n",
        "\n",
        "[8] O. Tuzel, F. Porikli, and P. Meer, “Learning on Lie groups for invariant detection and tracking,” *Proc. 2008 IEEE CVPR*, pp. 1–8, June 2008. [Link](https://doi.org/10.1109/CVPR.2008.4587521)\n",
        "\n",
        "[9] A. Barrau and S. Bonnabel, “Intrinsic filtering on Lie groups with applications to attitude estimation,” *IEEE Trans. Automatic Control*, 60(2):436–449, Feb 2015. [Link](https://doi.org/10.1109/TAC.2014.2342911)\n",
        "\n",
        "[10] S. Bonnabel and A. Barrau, “An intrinsic Cramér–Rao bound on SO(3) for (dynamic) attitude filtering,” *Proc. 54th IEEE CDC*, pp. 2158–2163, Dec 2015. [Link](https://dblp.org/rec/conf/cdc/BonnabelB15)\n",
        "\n",
        "[11] A. Barrau and S. Bonnabel, “The invariant extended Kalman filter as a stable observer,” *IEEE Trans. Automatic Control*, 62(4):1797–1812, Apr 2017. [Link](https://doi.org/10.1109/TAC.2016.2594085)\n",
        "\n",
        "[12] C. Lageman, J. Trumpf, and R. Mahony, “Gradient-like observers for invariant dynamics on a Lie group,” *IEEE Trans. Automatic Control*, 55(2):367–377, Feb 2010. [Link](https://doi.org/10.1109/TAC.2009.2034937)\n",
        "\n",
        "[13] S. Bonnabel, P. Martin, and P. Rouchon, “Non-linear symmetry-preserving observers on Lie groups,” *IEEE Trans. Automatic Control*, 54(7):1709–1713, July 2009. [Link](https://doi.org/10.1109/TAC.2009.2020646)\n",
        "\n",
        "[14] M. Izadi and A. K. Sanyal, “Rigid body attitude estimation based on the Lagrange–d’Alembert principle,” *Automatica*, 50(10):2570–2577, 2014. [Link](https://doi.org/10.1016/j.automatica.2014.08.010)\n",
        "\n",
        "[15] S. Bonnabel and J. J. Slotine, “A contraction theory-based analysis of the stability of the deterministic extended Kalman filter,” *IEEE Trans. Automatic Control*, 60(2):565–569, Feb 2015. [Link](https://doi.org/10.1109/TAC.2014.2336991)\n"
      ],
      "metadata": {
        "id": "GRmtfWDYt4PH"
      }
    }
  ]
}