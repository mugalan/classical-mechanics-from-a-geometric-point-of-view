{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mugalan/classical-mechanics-from-a-geometric-point-of-view/blob/main/supplementary/vector_spaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector Spaces"
      ],
      "metadata": {
        "id": "xfLSTR5HEaMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition"
      ],
      "metadata": {
        "id": "46ewuaQcLk_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **vector space** (also known as a **linear space**) is a fundamental concept in mathematics, particularly in linear algebra. It is a set that is equipped with two operations: vector addition and scalar multiplication. The set and these operations must satisfy a number of specific properties or axioms. Here's a formal definition:\n",
        "\n",
        "### Definition of a Vector Space\n",
        "\n",
        "A **vector space** $ V $ over a field $ F $ (such as the real numbers $ \\mathbb{R} $ or complex numbers $ \\mathbb{C} $) is a set along with two operations:\n",
        "\n",
        "1. **Vector Addition**: An operation $ +: V \\times V \\rightarrow V $ that takes any two vectors $ u, v \\in V $ and returns a vector $ u + v \\in V $.\n",
        "2. **Scalar Multiplication**: An operation $ \\cdot : F \\times V \\rightarrow V $ that takes any scalar $ a \\in F $ and vector $ v \\in V $ and returns a vector $ a \\cdot v \\in V $.\n",
        "\n",
        "These operations must satisfy the following axioms for all vectors $ u, v, w \\in V $ and scalars $ a, b \\in F $:\n",
        "\n",
        "1. **Closure under Addition**: $ u + v \\in V $.\n",
        "2. **Associativity of Addition**: $ u + (v + w) = (u + v) + w $.\n",
        "3. **Commutativity of Addition**: $ u + v = v + u $.\n",
        "4. **Existence of an Additive Identity**: There exists an element $ 0 \\in V $ (called the zero vector) such that $ u + 0 = u $ for all $ u \\in V $.\n",
        "5. **Existence of Additive Inverses**: For each $ u \\in V $, there exists an element $ -u \\in V $ such that $ u + (-u) = 0 $.\n",
        "6. **Closure under Scalar Multiplication**: $ a \\cdot u \\in V $.\n",
        "7. **Compatibility of Scalar Multiplication with Field Multiplication**: $ a \\cdot (b \\cdot u) = (a \\cdot b) \\cdot u $.\n",
        "8. **Identity Element of Scalar Multiplication**: $ 1 \\cdot u = u $, where $ 1 $ is the multiplicative identity in $ F $.\n",
        "9. **Distributivity of Scalar Multiplication with respect to Vector Addition**: $ a \\cdot (u + v) = a \\cdot u + a \\cdot v $.\n",
        "10. **Distributivity of Scalar Multiplication with respect to Field Addition**: $ (a + b) \\cdot u = a \\cdot u + b \\cdot u $.\n",
        "\n",
        "A set $ V $ that satisfies these properties, along with its defined operations, constitutes a vector space over the field $ F $."
      ],
      "metadata": {
        "id": "HTjynt6wLn87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples"
      ],
      "metadata": {
        "id": "z4x8JX4yL6iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Here are several distinct types of examples of vector spaces:\n",
        "\n",
        "### 1. **Real Coordinate Space ($ \\mathbb{R}^n $)**\n",
        "\n",
        "**Definition**: The set of all ordered $ n $-tuples of real numbers, denoted by $ \\mathbb{R}^n $.\n",
        "\n",
        "- **Elements**: Vectors are of the form $ (x_1, x_2, \\ldots, x_n) $ where each $ x_i \\in \\mathbb{R} $.\n",
        "- **Operations**:\n",
        "  - **Vector Addition**: $ (x_1, x_2, \\ldots, x_n) + (y_1, y_2, \\ldots, y_n) = (x_1 + y_1, x_2 + y_2, \\ldots, x_n + y_n) $.\n",
        "  - **Scalar Multiplication**: $ a \\cdot (x_1, x_2, \\ldots, x_n) = (a \\cdot x_1, a \\cdot x_2, \\ldots, a \\cdot x_n) $ for $ a \\in \\mathbb{R} $.\n",
        "\n",
        "**Example**: $ \\mathbb{R}^2 $ is the set of all ordered pairs of real numbers, often visualized as the model for the 2D plane. $ \\mathbb{R}^3 $ is the set of all ordered triples of real numbers, visualized as the model for the 3D space.\n",
        "\n",
        "### 2. **Complex Coordinate Space ($ \\mathbb{C}^n $)**\n",
        "\n",
        "**Definition**: The set of all ordered $ n $-tuples of complex numbers, denoted by $ \\mathbb{C}^n $.\n",
        "\n",
        "- **Elements**: Vectors are of the form $ (z_1, z_2, \\ldots, z_n) $ where each $ z_i \\in \\mathbb{C} $.\n",
        "- **Operations**:\n",
        "  - **Vector Addition**: $ (z_1, z_2, \\ldots, z_n) + (w_1, w_2, \\ldots, w_n) = (z_1 + w_1, z_2 + w_2, \\ldots, z_n + w_n) $.\n",
        "  - **Scalar Multiplication**: $ a \\cdot (z_1, z_2, \\ldots, z_n) = (a \\cdot z_1, a \\cdot z_2, \\ldots, a \\cdot z_n) $ for $ a \\in \\mathbb{C} $.\n",
        "\n",
        "**Example**: $ \\mathbb{C}^2 $ is the set of all ordered pairs of complex numbers.\n",
        "\n",
        "### 3. **Polynomial Space ($ P_n $)**\n",
        "\n",
        "**Definition**: The set of all polynomials of degree less than or equal to $ n $ with coefficients in a field $ F $, denoted by $ P_n(F) $.\n",
        "\n",
        "- **Elements**: Polynomials of the form $ a_0 + a_1 x + a_2 x^2 + \\ldots + a_n x^n $, where $ a_i \\in F $.\n",
        "- **Operations**:\n",
        "  - **Vector Addition**: $ (a_0 + a_1 x + \\ldots + a_n x^n) + (b_0 + b_1 x + \\ldots + b_n x^n) = (a_0 + b_0) + (a_1 + b_1)x + \\ldots + (a_n + b_n)x^n $.\n",
        "  - **Scalar Multiplication**: $ c \\cdot (a_0 + a_1 x + \\ldots + a_n x^n) = (c a_0) + (c a_1)x + \\ldots + (c a_n)x^n $ for $ c \\in F $.\n",
        "\n",
        "**Example**: $ P_2(\\mathbb{R}) $ is the space of all quadratic polynomials with real coefficients, such as $ 2 + 3x - x^2 $.\n",
        "\n",
        "### 4. **Matrix Space ($ M_{m \\times n}(F) $)**\n",
        "\n",
        "**Definition**: The set of all $ m \\times n $ matrices with entries in a field $ F $, denoted by $ M_{m \\times n}(F) $.\n",
        "\n",
        "- **Elements**: Matrices of the form $ A = [a_{ij}] $ where $ a_{ij} \\in F $ for $ 1 \\leq i \\leq m $ and $ 1 \\leq j \\leq n $.\n",
        "- **Operations**:\n",
        "  - **Matrix Addition**: $ [a_{ij}] + [b_{ij}] = [a_{ij} + b_{ij}] $.\n",
        "  - **Scalar Multiplication**: $ c \\cdot [a_{ij}] = [c \\cdot a_{ij}] $ for $ c \\in F $.\n",
        "\n",
        "**Example**: $ M_{2 \\times 2}(\\mathbb{R}) $ is the space of all 2x2 matrices with real entries.\n",
        "\n",
        "### 5. **Function Space ($ C[a, b] $)**\n",
        "\n",
        "**Definition**: The set of all continuous functions defined on a closed interval $[a, b]$ with values in $ \\mathbb{R} $, denoted by $ C[a, b] $.\n",
        "\n",
        "- **Elements**: Continuous functions $ f: [a, b] \\rightarrow \\mathbb{R} $.\n",
        "- **Operations**:\n",
        "  - **Function Addition**: $ (f + g)(x) = f(x) + g(x) $.\n",
        "  - **Scalar Multiplication**: $ (c \\cdot f)(x) = c \\cdot f(x) $ for $ c \\in \\mathbb{R} $.\n",
        "\n",
        "**Example**: The set of all continuous functions from the interval $[0, 1]$ to $\\mathbb{R}$.\n",
        "\n",
        "### 6. **Infinite-Dimensional Sequence Space ($ l^2 $)**\n",
        "\n",
        "**Definition**: The set of all infinite sequences of real numbers $ (a_1, a_2, a_3, \\ldots) $ such that the series $ \\sum_{i=1}^\\infty |a_i|^2 $ converges, denoted by $ l^2 $.\n",
        "\n",
        "- **Elements**: Sequences $ (a_1, a_2, a_3, \\ldots) $ with $ \\sum_{i=1}^\\infty |a_i|^2 < \\infty $.\n",
        "- **Operations**:\n",
        "  - **Sequence Addition**: $ (a_1, a_2, \\ldots) + (b_1, b_2, \\ldots) = (a_1 + b_1, a_2 + b_2, \\ldots) $.\n",
        "  - **Scalar Multiplication**: $ c \\cdot (a_1, a_2, \\ldots) = (c \\cdot a_1, c \\cdot a_2, \\ldots) $ for $ c \\in \\mathbb{R} $.\n",
        "\n",
        "**Example**: The space $ l^2 $ is used in functional analysis and quantum mechanics, where sequences represent states or wavefunctions.\n",
        "\n",
        "### 7. **Set of All Linear Transformations**\n",
        "\n",
        "**Definition**: The set of all linear transformations from one vector space $ V $ to another vector space $ W $, denoted by $ \\text{Hom}(V, W) $.\n",
        "\n",
        "- **Elements**: Linear transformations (functions) $ T: V \\rightarrow W $ that satisfy linearity.\n",
        "- **Operations**:\n",
        "  - **Addition of Transformations**: $ (T_1 + T_2)(v) = T_1(v) + T_2(v) $ for all $ v \\in V $.\n",
        "  - **Scalar Multiplication**: $ (c \\cdot T)(v) = c \\cdot T(v) $ for $ c \\in F $ and all $ v \\in V $.\n",
        "\n",
        "**Example**: The space of all $ 2 \\times 2 $ matrices can be seen as the set of all linear transformations from $ \\mathbb{R}^2 $ to itself.\n",
        "\n",
        "These examples illustrate a variety of vector spaces, including finite-dimensional, infinite-dimensional, function spaces, and spaces of transformations, each with distinct elements and operations but all satisfying the vector space axioms."
      ],
      "metadata": {
        "id": "jjIWrQWoMGdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The example of a $ 3 \\times 3$ skew-symmetric matrices $so (3)$"
      ],
      "metadata": {
        "id": "vZevC9fQNX_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **skew-symmetric matrix** (also known as an **antisymmetric matrix**) is a square matrix $ A $ that satisfies the condition $ A^T = -A $, where $ A^T $ is the transpose of $ A $. This means that for all elements $ a_{ij} $ in the matrix, $ a_{ij} = -a_{ji} $. Consequently, all diagonal elements of a skew-symmetric matrix must be zero (since $ a_{ii} = -a_{ii} $ implies $ a_{ii} = 0 $).\n",
        "\n",
        "### Example of a 3Ã—3 Skew-Symmetric Matrix\n",
        "\n",
        "A general form of a $ 3 \\times 3 $ skew-symmetric matrix can be written as:\n",
        "\n",
        "\\begin{align}\n",
        "A = \\begin{bmatrix}\n",
        "0 & a & b \\\\\n",
        "-a & 0 & c \\\\\n",
        "-b & -c & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "where $ a, b, $ and $ c $ are any real numbers.\n",
        "\n",
        "Here is a specific example of a $ 3 \\times 3 $ skew-symmetric matrix:\n",
        "\n",
        "\\begin{align}\n",
        "A = \\begin{bmatrix}\n",
        "0 & 2 & -3 \\\\\n",
        "-2 & 0 & 4 \\\\\n",
        "3 & -4 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "#### Verification:\n",
        "\n",
        "1. **Transpose** of matrix $ A $ is:\n",
        "\n",
        "\\begin{align}\n",
        "A^T = \\begin{bmatrix}\n",
        "0 & -2 & 3 \\\\\n",
        "2 & 0 & -4 \\\\\n",
        "-3 & 4 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "2. **Negative of the transpose** of matrix $ A $ is:\n",
        "\n",
        "\\begin{align}\n",
        "-A = \\begin{bmatrix}\n",
        "0 & -2 & 3 \\\\\n",
        "2 & 0 & -4 \\\\\n",
        "-3 & 4 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Since $ A^T = -A $, the matrix $ A $ is indeed skew-symmetric.\n",
        "\n",
        "### Properties of Skew-Symmetric Matrices\n",
        "\n",
        "1. **Zero Diagonal**: All diagonal elements of a skew-symmetric matrix are zero.\n",
        "   \n",
        "2. **Odd-Dimensional Determinant**: The determinant of a skew-symmetric matrix of odd order (like $ 3 \\times 3 $) is always zero.\n",
        "\n",
        "3. **Eigenvalues**: All eigenvalues of a skew-symmetric matrix are either zero or purely imaginary (of the form $ \\pm i \\lambda $ where $ \\lambda \\in \\mathbb{R} $).\n",
        "\n",
        "These properties make skew-symmetric matrices particularly interesting in various applications, including physics and computer graphics, where they often represent rotations and angular velocities."
      ],
      "metadata": {
        "id": "8aD7CZ0oNfeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proof that $so(3)$ is a vector space"
      ],
      "metadata": {
        "id": "L2sj8lVZNjIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Closure under Addition**:\n",
        "\n",
        "   Let $ A, B \\in V $ be two skew-symmetric matrices. By definition, $ A^T = -A $ and $ B^T = -B $.\n",
        "\n",
        "   Consider $ A + B $:\n",
        "   \\begin{align}\n",
        "   (A + B)^T = A^T + B^T = (-A) + (-B) = -(A + B).\n",
        "   \\end{align}\n",
        "\n",
        "   Thus, $ A + B $ is also skew-symmetric, so $ A + B \\in V $.\n",
        "\n",
        "2. **Closure under Scalar Multiplication**:\n",
        "\n",
        "   Let $ A \\in V $ and let $ c $ be a scalar.\n",
        "\n",
        "   Consider $ cA $:\n",
        "   \\begin{align}\n",
        "   (cA)^T = cA^T = c(-A) = -(cA).\n",
        "   \\end{align}\n",
        "\n",
        "   Thus, $ cA $ is also skew-symmetric, so $ cA \\in V $.\n",
        "\n",
        "3. **Associativity of Addition**:\n",
        "\n",
        "   Matrix addition is associative for all matrices, including skew-symmetric ones. For any $ A, B, C \\in V $:\n",
        "   \\begin{align}\n",
        "   (A + B) + C = A + (B + C).\n",
        "   \\end{align}\n",
        "\n",
        "4. **Commutativity of Addition**:\n",
        "\n",
        "   Matrix addition is commutative for all matrices, including skew-symmetric ones. For any $ A, B \\in V $:\n",
        "   \\begin{align}\n",
        "   A + B = B + A.\n",
        "   \\end{align}\n",
        "\n",
        "5. **Existence of Additive Identity**:\n",
        "\n",
        "   The zero matrix $ O $, where all elements are zero, is skew-symmetric because $ O^T = O = -O $. For any $ A \\in V $:\n",
        "   \\begin{align}\n",
        "   A + O = A.\n",
        "   \\end{align}\n",
        "\n",
        "   Thus, the zero matrix is the additive identity.\n",
        "\n",
        "6. **Existence of Additive Inverses**:\n",
        "\n",
        "   For any $ A \\in V $, $ -A $ is also skew-symmetric because:\n",
        "   \\begin{align}\n",
        "   (-A)^T = -A^T = -(-A) = A.\n",
        "   \\end{align}\n",
        "\n",
        "   Moreover:\n",
        "   \\begin{align}\n",
        "   A + (-A) = O.\n",
        "   \\end{align}\n",
        "\n",
        "   Thus, $ -A $ is the additive inverse of $ A $.\n",
        "\n",
        "7. **Distributivity of Scalar Multiplication with respect to Vector Addition**:\n",
        "\n",
        "   For any scalar $ c $ and matrices $ A, B \\in V $:\n",
        "   \\begin{align}\n",
        "   c(A + B) = cA + cB.\n",
        "   \\end{align}\n",
        "\n",
        "   This is a property of matrix scalar multiplication.\n",
        "\n",
        "8. **Distributivity of Scalar Multiplication with respect to Field Addition**:\n",
        "\n",
        "   For any scalars $ c, d $ and matrix $ A \\in V $:\n",
        "   \\begin{align}\n",
        "   (c + d)A = cA + dA.\n",
        "   \\end{align}\n",
        "\n",
        "   This is a property of matrix scalar multiplication.\n",
        "\n",
        "9. **Compatibility of Scalar Multiplication with Field Multiplication**:\n",
        "\n",
        "   For any scalars $ c, d $ and matrix $ A \\in V $:\n",
        "   \\begin{align}\n",
        "   c(dA) = (cd)A.\n",
        "   \\end{align}\n",
        "\n",
        "   This is a property of matrix scalar multiplication.\n",
        "\n",
        "10. **Identity Element of Scalar Multiplication**:\n",
        "\n",
        "    For any matrix $ A \\in V $:\n",
        "    \\begin{align}\n",
        "    1A = A.\n",
        "    \\end{align}\n",
        "\n",
        "    This is a property of scalar multiplication with the multiplicative identity 1.\n",
        "\n",
        "### $so(3)$ is a Vectorspace\n",
        "\n",
        "Since the set of all $ 3 \\times 3 $ skew-symmetric matrices satisfies all the axioms for a vector space under matrix addition and scalar multiplication, it forms a vector space."
      ],
      "metadata": {
        "id": "VnxQxkpaNt2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The space of directoed line segments in space"
      ],
      "metadata": {
        "id": "pkmfCyCpQH0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demonstrate the relationship between the **equivalence classes of directed line segments**, the **parallelogram law**, and the **$i, j, k$ representation** in 3-dimensional space, let's break down each concept and show how they are interconnected in the context of vector spaces.\n",
        "\n",
        "### 1. The $i, j, k$ Representation of Vectors\n",
        "\n",
        "In 3-dimensional space, any vector can be represented as a linear combination of the standard basis vectors:\n",
        "\n",
        "- **$i$**: A unit vector in the direction of the x-axis, represented as $ (1, 0, 0) $.\n",
        "- **$j$**: A unit vector in the direction of the y-axis, represented as $ (0, 1, 0) $.\n",
        "- **$k$**: A unit vector in the direction of the z-axis, represented as $ (0, 0, 1) $.\n",
        "\n",
        "A vector $ \\mathbf{v} $ in $ \\mathbb{R}^3 $ can be expressed as:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{v} = v_1 \\mathbf{i} + v_2 \\mathbf{j} + v_3 \\mathbf{k},\n",
        "\\end{align}\n",
        "\n",
        "where $ v_1, v_2, $ and $ v_3 $ are the components of the vector along the x, y, and z axes, respectively.\n",
        "\n",
        "### 2. Parallelogram Law for Vector Addition\n",
        "\n",
        "The **parallelogram law** states that if two vectors $ \\mathbf{u} $ and $ \\mathbf{v} $ are placed tail-to-tail, then the sum $ \\mathbf{u} + \\mathbf{v} $ is represented by the diagonal of the parallelogram that has $ \\mathbf{u} $ and $ \\mathbf{v} $ as its adjacent sides.\n",
        "\n",
        "In vector form:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{u} = u_1 \\mathbf{i} + u_2 \\mathbf{j} + u_3 \\mathbf{k}, \\quad \\mathbf{v} = v_1 \\mathbf{i} + v_2 \\mathbf{j} + v_3 \\mathbf{k}.\n",
        "\\end{align}\n",
        "\n",
        "The sum $ \\mathbf{u} + \\mathbf{v} $ is:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{u} + \\mathbf{v} = (u_1 + v_1) \\mathbf{i} + (u_2 + v_2) \\mathbf{j} + (u_3 + v_3) \\mathbf{k}.\n",
        "\\end{align}\n",
        "\n",
        "### 3. Demonstrating the Relationship Using Directed Line Segments\n",
        "\n",
        "Consider two directed line segments, represented by vectors $ \\mathbf{u} $ and $ \\mathbf{v} $, originating from a common point (say the origin, $ (0, 0, 0) $) in 3D space:\n",
        "\n",
        "- **Vector $ \\mathbf{u} $**: Points from the origin to point $ A = (u_1, u_2, u_3) $.\n",
        "- **Vector $ \\mathbf{v} $**: Points from the origin to point $ B = (v_1, v_2, v_3) $.\n",
        "\n",
        "To find the vector sum $ \\mathbf{u} + \\mathbf{v} $, we place the tail of vector $ \\mathbf{v} $ at the head of vector $ \\mathbf{u} $. The resulting vector, drawn from the tail of $ \\mathbf{u} $ to the head of $ \\mathbf{v} $, represents $ \\mathbf{u} + \\mathbf{v} $.\n",
        "\n",
        "#### Geometric Interpretation:\n",
        "\n",
        "1. **Placing Vectors in Standard Position**:\n",
        "\n",
        "   Both vectors start from the origin:\n",
        "   \\begin{align}\n",
        "   \\mathbf{u} = u_1 \\mathbf{i} + u_2 \\mathbf{j} + u_3 \\mathbf{k}, \\quad \\mathbf{v} = v_1 \\mathbf{i} + v_2 \\mathbf{j} + v_3 \\mathbf{k}.\n",
        "   \\end{align}\n",
        "\n",
        "2. **Applying the Parallelogram Law**:\n",
        "\n",
        "   By placing the vectors tail-to-tail, the parallelogram is formed by drawing lines parallel to $ \\mathbf{u} $ and $ \\mathbf{v} $ starting from the endpoints of each vector. The diagonal of this parallelogram represents the vector $ \\mathbf{u} + \\mathbf{v} $:\n",
        "\n",
        "   \\begin{align}\n",
        "   \\mathbf{u} + \\mathbf{v} = (u_1 + v_1) \\mathbf{i} + (u_2 + v_2) \\mathbf{j} + (u_3 + v_3) \\mathbf{k}.\n",
        "   \\end{align}\n",
        "\n",
        "3. **Calculating the Resulting Vector**:\n",
        "\n",
        "   The resulting vector $ \\mathbf{u} + \\mathbf{v} $ ends at the point $ (u_1 + v_1, u_2 + v_2, u_3 + v_3) $.\n",
        "\n",
        "### 4. Connecting the Concepts\n",
        "\n",
        "- **Equivalence Class of Directed Line Segments**: Vectors $ \\mathbf{u} $ and $ \\mathbf{v} $ are represented as equivalence classes of directed line segments based on their magnitude and direction.\n",
        "- **$i, j, k$ Representation**: The components $ u_1, u_2, u_3 $ and $ v_1, v_2, v_3 $ are the coordinates in the $i, j, k$ basis that describe each vector.\n",
        "- **Parallelogram Law**: The sum $ \\mathbf{u} + \\mathbf{v} $ forms the diagonal of the parallelogram defined by vectors $ \\mathbf{u} $ and $ \\mathbf{v} $.\n",
        "\n",
        "### Example\n",
        "\n",
        "Let's consider two specific vectors:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{u} = 2\\mathbf{i} + 3\\mathbf{j} + \\mathbf{k}, \\quad \\mathbf{v} = \\mathbf{i} - 2\\mathbf{j} + 4\\mathbf{k}.\n",
        "\\end{align}\n",
        "\n",
        "Using the $i, j, k$ representation, compute their sum:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{u} + \\mathbf{v} = (2 + 1) \\mathbf{i} + (3 - 2) \\mathbf{j} + (1 + 4) \\mathbf{k} = 3\\mathbf{i} + \\mathbf{j} + 5\\mathbf{k}.\n",
        "\\end{align}\n",
        "\n",
        "- **Geometrically**, the vector $ \\mathbf{u} + \\mathbf{v} $ represents the diagonal of a parallelogram formed by the two original vectors when placed tail-to-tail.\n",
        "- **In vector notation**, the result follows directly from adding their corresponding components in the $i, j, k$ representation.\n",
        "\n",
        "\n",
        "The **equivalence classes of directed line segments**, the **parallelogram law**, and the **$i, j, k$ representation** are all interconnected through the concept of vectors in 3-dimensional space. The $i, j, k$ representation provides a concrete way to perform operations on vectors, while the parallelogram law gives a geometric interpretation of vector addition."
      ],
      "metadata": {
        "id": "ndCmpfBrQMtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inner Product on a Vector Space"
      ],
      "metadata": {
        "id": "v--0nxMtSR3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **inner product** on a vector space is a function that associates each pair of vectors in the space with a scalar, satisfying certain properties. The inner product provides a way to define geometric concepts like length and angle in vector spaces.\n",
        "\n",
        "### Definition of an Inner Product\n",
        "\n",
        "Let $ V $ be a vector space over the field $ \\mathbb{R} $ (real numbers) or $ \\mathbb{C} $ (complex numbers). An **inner product** on $ V $ is a function\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle \\cdot, \\cdot \\rangle\\rangle : V \\times V \\to \\mathbb{R} \\quad \\text{(or } \\mathbb{C} \\text{)}\n",
        "\\end{align}\n",
        "\n",
        "that satisfies the following properties for all vectors $ \\mathbf{u}, \\mathbf{v}, \\mathbf{w} \\in V $ and all scalars $ c \\in \\mathbb{R} $ (or $ \\mathbb{C} $):\n",
        "\n",
        "1. **Conjugate Symmetry**:  \n",
        "   \\begin{align}\n",
        "   \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle = \\overline{\\langle\\langle \\mathbf{v}, \\mathbf{u} \\rangle\\rangle},\n",
        "   \\end{align}\n",
        "   where $ \\overline{\\langle\\langle \\mathbf{v}, \\mathbf{u} \\rangle\\rangle} $ denotes the complex conjugate of $ \\langle\\langle \\mathbf{v}, \\mathbf{u} \\rangle\\rangle $. In the case of a real vector space, this property reduces to:\n",
        "   \\begin{align}\n",
        "   \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle = \\langle\\langle \\mathbf{v}, \\mathbf{u} \\rangle\\rangle.\n",
        "   \\end{align}\n",
        "\n",
        "2. **Linearity in the First Argument** (or **Conjugate Linearity** for complex vector spaces):\n",
        "   \\begin{align}\n",
        "   \\langle\\langle c \\mathbf{u} + \\mathbf{v}, \\mathbf{w} \\rangle\\rangle = c \\langle\\langle \\mathbf{u}, \\mathbf{w} \\rangle\\rangle + \\langle\\langle \\mathbf{v}, \\mathbf{w} \\rangle\\rangle.\n",
        "   \\end{align}\n",
        "   If the vector space is over $ \\mathbb{C} $, then linearity in the first argument is replaced by:\n",
        "   \\begin{align}\n",
        "   \\langle\\langle c \\mathbf{u} + \\mathbf{v}, \\mathbf{w} \\rangle\\rangle = c \\langle\\langle \\mathbf{u}, \\mathbf{w} \\rangle\\rangle + \\langle\\langle \\mathbf{v}, \\mathbf{w} \\rangle\\rangle.\n",
        "   \\end{align}\n",
        "\n",
        "3. **Positive-Definiteness**:\n",
        "   \\begin{align}\n",
        "   \\langle\\langle \\mathbf{v}, \\mathbf{v} \\rangle\\rangle \\geq 0,\n",
        "   \\end{align}\n",
        "   and $ \\langle\\langle \\mathbf{v}, \\mathbf{v} \\rangle\\rangle = 0 $ if and only if $ \\mathbf{v} = \\mathbf{0} $.\n",
        "\n",
        "### Geometric Interpretation\n",
        "\n",
        "The inner product $ \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle $ provides a way to measure the \"angle\" between two vectors and their \"lengths\" (or magnitudes). For example:\n",
        "\n",
        "- The **length** (or norm) of a vector $ \\mathbf{v} $ is given by $ \\|\\mathbf{v}\\| = \\sqrt{\\langle\\langle \\mathbf{v}, \\mathbf{v} \\rangle\\rangle} $.\n",
        "- Two vectors $ \\mathbf{u} $ and $ \\mathbf{v} $ are **orthogonal** (perpendicular) if $ \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle = 0 $.\n",
        "\n",
        "### Examples\n",
        "\n",
        "1. **Euclidean Inner Product** in $ \\mathbb{R}^n $:\n",
        "\n",
        "   For vectors $ \\mathbf{u} = (u_1, u_2, \\ldots, u_n) $ and $ \\mathbf{v} = (v_1, v_2, \\ldots, v_n) $ in $ \\mathbb{R}^n $, the inner product is defined as:\n",
        "\n",
        "   \\begin{align}\n",
        "   \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle = u_1 v_1 + u_2 v_2 + \\cdots + u_n v_n.\n",
        "   \\end{align}\n",
        "\n",
        "2. **Complex Inner Product** in $ \\mathbb{C}^n $:\n",
        "\n",
        "   For vectors $ \\mathbf{u} = (u_1, u_2, \\ldots, u_n) $ and $ \\mathbf{v} = (v_1, v_2, \\ldots, v_n) $ in $ \\mathbb{C}^n $, the inner product is defined as:\n",
        "\n",
        "   \\begin{align}\n",
        "   \\langle\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\rangle = u_1 \\overline{v_1} + u_2 \\overline{v_2} + \\cdots + u_n \\overline{v_n},\n",
        "   \\end{align}\n",
        "\n",
        "   where $ \\overline{v_i} $ denotes the complex conjugate of $ v_i $.\n",
        "\n",
        "By satisfying these properties, the inner product structure provides a foundation for many geometric and algebraic concepts in vector spaces."
      ],
      "metadata": {
        "id": "PQPbRZNTSXz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inner Product on $so(3)$"
      ],
      "metadata": {
        "id": "I75c7r4fT5_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define an inner product on the vector space of $3 \\times 3$ skew-symmetric matrices, we will use the expression $-\\frac{1}{2} \\text{tr}(AB)$. We will prove that this expression satisfies all the properties of an inner product without explicitly computing the product of two matrices. Instead, we will use properties of the trace and skew-symmetric matrices.\n",
        "\n",
        "### Definition of Inner Product on Skew-Symmetric Matrices\n",
        "\n",
        "Let $A$ and $B$ be $3 \\times 3$ skew-symmetric matrices. The proposed inner product is:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, B \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(AB).\n",
        "\\end{align}\n",
        "\n",
        "### Properties of Skew-Symmetric Matrices and Trace\n",
        "\n",
        "Recall that a matrix $A$ is **skew-symmetric** if $A^T = -A$. Skew-symmetric matrices have the following properties:\n",
        "\n",
        "1. **Diagonal elements are zero**: $a_{ii} = 0$.\n",
        "2. **Transpose property**: $A^T = -A$.\n",
        "3. **Trace of a matrix**: For any square matrix $M$, the trace $\\text{tr}(M)$ is the sum of its diagonal elements.\n",
        "\n",
        "### Inner Product Properties to Verify\n",
        "\n",
        "To show that $\\langle\\langle A, B \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(AB)$ defines a valid inner product on the vector space of $3 \\times 3$ skew-symmetric matrices, we need to verify the following properties:\n",
        "\n",
        "1. **Conjugate Symmetry**: $\\langle\\langle A, B \\rangle\\rangle = \\overline{\\langle\\langle B, A \\rangle\\rangle}$.\n",
        "2. **Linearity in the First Argument**: $\\langle\\langle cA + B, C \\rangle\\rangle = c\\langle\\langle A, C \\rangle\\rangle + \\langle\\langle B, C \\rangle\\rangle$ for any scalar $c$.\n",
        "3. **Positive-Definiteness**: $\\langle\\langle A, A \\rangle\\rangle \\geq 0$ and $\\langle\\langle A, A \\rangle\\rangle = 0$ if and only if $A = 0$.\n",
        "\n",
        "### 1. Conjugate Symmetry\n",
        "\n",
        "For matrices $A$ and $B$, we need to show:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, B \\rangle\\rangle = \\overline{\\langle\\langle B, A \\rangle\\rangle}.\n",
        "\\end{align}\n",
        "\n",
        "Since $A$ and $B$ are real skew-symmetric matrices:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, B \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(AB).\n",
        "\\end{align}\n",
        "\n",
        "Using the property of the trace $\\text{tr}(AB) = \\text{tr}(BA)$, we get:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle B, A \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(BA) = -\\frac{1}{2} \\text{tr}(AB) = \\langle\\langle A, B \\rangle\\rangle.\n",
        "\\end{align}\n",
        "\n",
        "Thus, $\\langle\\langle A, B \\rangle\\rangle = \\langle\\langle B, A \\rangle\\rangle$, satisfying the conjugate symmetry condition (for real matrices, this means they are symmetric in terms).\n",
        "\n",
        "### 2. Linearity in the First Argument\n",
        "\n",
        "We need to show:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle cA + B, C \\rangle\\rangle = c\\langle\\langle A, C \\rangle\\rangle + \\langle\\langle B, C \\rangle\\rangle.\n",
        "\\end{align}\n",
        "\n",
        "Compute the inner product:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle cA + B, C \\rangle\\rangle = -\\frac{1}{2} \\text{tr}((cA + B)C).\n",
        "\\end{align}\n",
        "\n",
        "Using linearity of matrix multiplication and trace:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{tr}((cA + B)C) = \\text{tr}(cAC + BC) = c \\text{tr}(AC) + \\text{tr}(BC).\n",
        "\\end{align}\n",
        "\n",
        "Then:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle cA + B, C \\rangle\\rangle = -\\frac{1}{2}(c \\text{tr}(AC) + \\text{tr}(BC)).\n",
        "\\end{align}\n",
        "\n",
        "Distributing the $-\\frac{1}{2}$:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle cA + B, C \\rangle\\rangle = c(-\\frac{1}{2} \\text{tr}(AC)) + (-\\frac{1}{2} \\text{tr}(BC)).\n",
        "\\end{align}\n",
        "\n",
        "So:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle cA + B, C \\rangle\\rangle = c \\langle\\langle A, C \\rangle\\rangle + \\langle\\langle B, C \\rangle\\rangle.\n",
        "\\end{align}\n",
        "\n",
        "This confirms linearity in the first argument.\n",
        "\n",
        "### 3. Positive-Definiteness\n",
        "\n",
        "We need to show:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, A \\rangle\\rangle \\geq 0 \\quad \\text{and} \\quad \\langle\\langle A, A \\rangle\\rangle = 0 \\text{ if and only if } A = 0.\n",
        "\\end{align}\n",
        "\n",
        "Compute the inner product:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, A \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(AA).\n",
        "\\end{align}\n",
        "\n",
        "Note that $AA^T = -A^2$ and since $A$ is skew-symmetric, $A^T = -A$ and $A^2$ is symmetric and negative semi-definite.\n",
        "\n",
        "For any skew-symmetric matrix $A$:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{tr}(A^2) \\leq 0.\n",
        "\\end{align}\n",
        "\n",
        "Since the trace of a symmetric negative semi-definite matrix $A^2$ is non-positive, $-\\frac{1}{2} \\text{tr}(A^2) \\geq 0$.\n",
        "\n",
        "Moreover, $\\langle\\langle A, A \\rangle\\rangle = 0$ if and only if $\\text{tr}(A^2) = 0$. Since $A^2$ is a positive semi-definite matrix, this implies $A = 0$.\n",
        "\n",
        "Thus, we conclude that:\n",
        "\n",
        "\\begin{align}\n",
        "\\langle\\langle A, A \\rangle\\rangle \\geq 0, \\quad \\text{and} \\quad \\langle\\langle A, A \\rangle\\rangle = 0 \\text{ if and only if } A = 0.\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "The expression $\\langle\\langle A, B \\rangle\\rangle = -\\frac{1}{2} \\text{tr}(AB)$ satisfies all the properties of an inner product on the vector space of $3 \\times 3$ skew-symmetric matrices: conjugate symmetry, linearity, and positive-definiteness. Therefore, it is a valid inner product."
      ],
      "metadata": {
        "id": "KBeA87ZjT-na"
      }
    }
  ]
}